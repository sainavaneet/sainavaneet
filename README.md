<img src="https://capsule-render.vercel.app/api?type=waving&color=20:0055ff,100:00eaff&height=220&section=header&text=Sai%20Navaneet&fontSize=52&fontAlign=70&fontAlignY=30&animation=fadeIn&fontColor=ffffff&desc=Specialised%20in%20Robotic%20Manipulation&descSize=22&descAlign=70&descAlignY=60" />

<p align="center">
  <b>Robotics Engineer â€¢ Vision-Language-Action Models â€¢ State-Space Architectures</b><br>
  I build intelligent robotic systems using VLA frameworks, Mamba-based models, and real-world robot platforms.
</p>

---

## ğŸš€ About Me
I'm focused on developing scalable Vision-Language-Action (VLA) models and applying advanced state-space architectures (Mamba, Kalman-Mamba, LegMamba) to real robotic systems.  
I have hands-on experience with manipulators, quadrupeds, AGVs, and multi-robot coordination.

I enjoy pushing the boundary between **robotics, machine learning, and embodied intelligence**.

---

## ğŸ“Š Contribution Visualizations

<p align="center">
  <img src="https://github.com/sainavaneet/sainavaneet/blob/output/github-contribution-grid-snake.svg">
</p>

---

## ğŸ›  Tech Stack

### **Robotics & Control**
<p>
  <img src="https://skillicons.dev/icons?i=ros,py,cpp,matlab,arduino" />
</p>

### **Machine Learning & VLA Models**
<p>
  <img src="https://skillicons.dev/icons?i=pytorch,tensorflow" />
</p>

### **Computer Vision & Simulation**
<p>
  <img src="https://skillicons.dev/icons?i=opencv,unity,blender" />
</p>

### **DevOps, Tools & OS**
<p>
  <img src="https://skillicons.dev/icons?i=docker,linux,git,github" />
</p>

---

## ğŸ§  Featured Projects

### ğŸ”¹ **MambaVLA â€“ Vision-Language-Action Model with State Space Architecture**
- VLA model using Mamba SSM + Eagle Vision Encoder + Qwen LLM  
- Handles complex manipulation & multi-step planning  
- Trained on LIBERO, Meta-World, RoboCasa tasks  

### ğŸ”¹ **DiffDAIL â€“ Diffusion-based Imitation Learning**
- Diffusion policy learning for real robot tasks  
- Robust to multi-modal sensor noise  
- Applied on Franka and ViperX manipulators  

### ğŸ”¹ **LegMamba â€“ Quadruped Locomotion with SSM**
- State-space locomotion model for Unitree Go2/A1  
- Stabilizes policies outdoors and on uneven terrain  
- Vision-conditioned gait modulation  

### ğŸ”¹ **Autonomous Manipulation & Multi-Robot Systems**
- Worked with Franka, ViperX, Go2, AGVs, diff-drive robots  
- Multi-arm coordination: Sim cube transfer, Libero tasks  
- RealSense RGB-D pipelines for grasping tasks  

---

## ğŸ“ˆ GitHub Stats

<p align="center">
  <img src="https://github-readme-stats-sigma-five.vercel.app/api?username=sainavaneet&show_icons=true&theme=transparent&rank_icon=percentile" width="48%" />
  <img src="https://streak-stats.demolab.com?user=sainavaneet&theme=transparent&border_radius=5" width="48%" />
</p>

---

## ğŸŒ Links
<p>
  <a href="https://sainavaneet.github.io/portfolio">ğŸ”— Portfolio</a> |
  <a href="https://github.com/sainavaneet">ğŸ™ GitHub</a> 
</p>

---
